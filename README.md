# Image-caption-generator-using-NLP
Image caption generator is a process of recognizing the context of an image and annotating it with relevant captions using deep learning and computer vision. 
It includes labeling an image with English keywords with the help of datasets provided during model training. The imagenet dataset trains the CNN model called Xception. 
Xception is responsible for image feature extraction. These extracted features will be fed to the LSTM model, which generates the image caption,To build an image caption
generator model we have to merge CNN with LSTM.
# Approach
>Dataset: 5 V’s of Data; Volume, Variety, Velocity, Veracity, Value are checked to ensure right set of data is collected for the problem statement.
>we are using the Flickr8k_dataset. The dataset contains two directories:
                   ----Flickr8k_Dataset: Contains 8092 photographs in JPEG format.
                   ----Flickr8k_text: Contains a number of files containing different sources of descriptions for the
                                                    photographs
>Import all the required packages 
>Perform data cleaning
>Extract the feature vector
>Loading dataset for model training
>Tokenizing the Vocabulary
>Create a Data generator
>Define the CNN-RNN model
>Training the Image Caption Generator model
>Testing the Image Caption Generator model
# Evaluation Methodology
>BLEU Score: BLEU checks how similar the captions generated by the model are to the actual captions. A higher BLEU score means the model's captions are closer to the real ones.
>METEOR: METEOR looks at both how many words the model gets right and how many it misses. A higher METEOR score shows the model does a better job at describing the images.
>Human Evaluation: People also look at the captions and decide if they make sense and match the images. This helps understand how well the model is doing from a human perspective.
# Conclusion
>Increased Training Epochs: Training the model for more epochs generally leads to improved accuracy and better results, as the model has more opportunities to learn from the data.
>Resource-Intensive Processing: Handling large datasets requires substantial time and system resources, necessitating careful planning and potentially specialized hardware.
>Deeper Models for Large Datasets: Increasing the number of layers in the model can be beneficial when working with extensive datasets like Flickr32k, as deeper models can capture more complex patterns.
>Challenges in Caption Generation: Generating accurate captions for images is inherently challenging, involving both visual and textual understanding.
>Promising Outcomes: Despite the challenges, the results obtained from the model are encouraging, indicating that the approach holds potential for further development.



